#!/usr/bin/env python3

import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image
from geometry_msgs.msg import Twist
from cv_bridge import CvBridge
import cv2
import numpy as np


class LineFollowerNode(Node):
    def __init__(self):
        super().__init__("line_follower_node")

        # CV Bridge for image conversion
        self.bridge = CvBridge()

        # Publishers and Subscribers
        self.cmd_vel_publisher = self.create_publisher(Twist, "/cmd_vel", 10)
        self.processed_image_publisher = self.create_publisher(
            Image, "/line_follower/processed_image", 10
        )
        self.image_subscriber = self.create_subscription(
            Image, "/camera/image_raw", self.image_callback, 10
        )

        # Parameters
        self.declare_parameter("linear_speed", 0.2)
        self.declare_parameter("angular_gain", 0.005)
        self.declare_parameter("roi_height_ratio", 0.5)  # Bottom 50% of image
        self.declare_parameter("roi_y_offset", 0.5)  # Start from 50% down (ë§¨ í•˜ë‹¨ 50%)
        self.declare_parameter("blur_kernel_size", 7)  # ì•½ê°„ ë” í¬ê²Œ
        self.declare_parameter("canny_low", 40)  # ë” ë‚®ì€ ì„ê³„ê°’ìœ¼ë¡œ ì•½í•œ edgeë„ ê²€ì¶œ
        self.declare_parameter("canny_high", 120)  # ë¹„ìœ¨ ìœ ì§€í•˜ë©´ì„œ ë‚®ì¶¤
        self.declare_parameter("min_line_length", 8)  # ë”ìš± ì§§ì€ ì ì„ ë„ ê²€ì¶œ
        self.declare_parameter("max_line_gap", 15)  # ë” ì´˜ì´˜í•œ ê°„ê²© ì—°ê²°
        self.declare_parameter("use_contour_detection", True)  # ìœ¤ê³½ì„  ê²€ì¶œ ì‚¬ìš©
        self.declare_parameter("white_line_detection", True)  # í°ìƒ‰ ì„  ê²€ì¶œ ëª¨ë“œ
        self.declare_parameter("brightness_threshold", 200)  # í°ìƒ‰ ì„  ì„ê³„ê°’
        self.declare_parameter("adaptive_threshold", True)  # ì ì‘ì  ì„ê³„ê°’ ì‚¬ìš©
        self.declare_parameter("contrast_enhancement", True)  # ëŒ€ë¹„ í–¥ìƒ ì‚¬ìš©
        self.declare_parameter("color_filtering", True)  # HSV ìƒ‰ìƒ í•„í„°ë§ ì‚¬ìš©
        self.declare_parameter(
            "saturation_max", 30
        )  # ì±„ë„ ìµœëŒ€ê°’ (ë‚®ì„ìˆ˜ë¡ í°ìƒ‰ì— ê°€ê¹Œì›€)
        self.declare_parameter("line_thinning", True)  # êµµì€ ì„ ì„ ì–‡ê²Œ ë§Œë“¤ê¸°
        self.declare_parameter("merge_close_lines", True)  # ê°€ê¹Œìš´ ì„ ë“¤ ë³‘í•©
        self.declare_parameter(
            "curve_detection_method", "contour"
        )  # 'hough', 'contour', 'moment', 'regression'
        self.declare_parameter("use_bgr_filtering", True)  # BGR + HSV ì¡°í•© í•„í„°ë§
        self.declare_parameter("separate_lanes", True)  # ì¢Œìš° ì°¨ì„  ë¶„ë¦¬ ê²€ì¶œ
        self.declare_parameter("use_linear_regression", True)  # ì„ í˜• íšŒê·€ ì‚¬ìš©
        self.declare_parameter("regression_min_points", 10)  # íšŒê·€ ìµœì†Œ ì  ê°œìˆ˜
        self.declare_parameter("adaptive_lane_width", True)  # ì ì‘ì  ì°¨ì„  í­ ì¶”ì •
        self.declare_parameter("curve_prediction", True)  # ì»¤ë¸Œì—ì„œ ì°¨ì„  ì˜ˆì¸¡
        self.declare_parameter("min_lane_width", 200)  # ìµœì†Œ ì°¨ì„  í­ (í”½ì…€)
        self.declare_parameter("max_lane_width", 500)  # ìµœëŒ€ ì°¨ì„  í­ (í”½ì…€)

        # PID Controller variables
        self.previous_error = 0.0
        self.integral_error = 0.0
        self.declare_parameter("kp", 0.8)
        self.declare_parameter("ki", 0.0)
        self.declare_parameter("kd", 0.1)

        # ì°¨ì„  í­ íˆìŠ¤í† ë¦¬ (ì ì‘ì  ì¶”ì •ìš©)
        self.lane_width_history = []
        self.max_history_size = 10

        self.get_logger().info("Line Follower Node started")

    def image_callback(self, msg):
        try:
            # Convert ROS Image to OpenCV
            cv_image = self.bridge.imgmsg_to_cv2(msg, "bgr8")

            # Process image to detect line
            line_center, processed_image = self.detect_line(cv_image)

            # Publish processed image for visualization
            self.publish_processed_image(processed_image)

            # Generate control command
            if line_center is not None:
                self.follow_line(line_center, cv_image.shape[1])
            else:
                self.stop_robot()

        except Exception as e:
            self.get_logger().error(f"Image processing error: {str(e)}")

    def detect_line(self, image):
        """Detect line using edge detection and Hough transform"""
        height, width = image.shape[:2]

        # Define ROI (Region of Interest) - bottom portion of image
        roi_height = int(height * self.get_parameter("roi_height_ratio").value)
        roi_y = int(height * self.get_parameter("roi_y_offset").value)

        # Create mask for ROI
        mask = np.zeros((height, width), dtype=np.uint8)
        mask[roi_y : roi_y + roi_height, :] = 255

        # Convert to grayscale
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

        # ê°•í™”ëœ ìƒ‰ìƒ í•„í„°ë§ (BGR + HSV ì¡°í•©ìœ¼ë¡œ í°ìƒ‰ ê²€ì¶œ)
        if self.get_parameter("color_filtering").value:
            white_color_mask = self.detect_white_lines_enhanced(image)
            # ì›ë³¸ ê·¸ë ˆì´ìŠ¤ì¼€ì¼ì— ìƒ‰ìƒ ë§ˆìŠ¤í¬ ì ìš©
            gray = cv2.bitwise_and(gray, gray, mask=white_color_mask)

        # Apply ROI mask
        masked_gray = cv2.bitwise_and(gray, mask)

        # ëŒ€ë¹„ í–¥ìƒ (íšŒìƒ‰ ë„ë¡œì™€ í°ìƒ‰ ì°¨ì„  êµ¬ë¶„ ê°•í™”)
        if self.get_parameter("contrast_enhancement").value:
            # CLAHE (Contrast Limited Adaptive Histogram Equalization) ì ìš©
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
            masked_gray = clahe.apply(masked_gray)

        # í°ìƒ‰ ì„  ê²€ì¶œì„ ìœ„í•œ ì „ì²˜ë¦¬
        if self.get_parameter("white_line_detection").value:
            if self.get_parameter("adaptive_threshold").value:
                # ì ì‘ì  ì„ê³„ê°’ ì²˜ë¦¬ (ì¡°ëª… ë³€í™”ì— ê°•í•¨)
                white_mask = cv2.adaptiveThreshold(
                    masked_gray,
                    255,
                    cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                    cv2.THRESH_BINARY,
                    15,
                    -5,  # ìŒìˆ˜ Cê°’ìœ¼ë¡œ ë°ì€ ë¶€ë¶„ë§Œ ì¶”ì¶œ
                )
            else:
                # ê³ ì • ì„ê³„ê°’ ì²˜ë¦¬
                brightness_threshold = self.get_parameter("brightness_threshold").value
                _, white_mask = cv2.threshold(
                    masked_gray, brightness_threshold, 255, cv2.THRESH_BINARY
                )

            # í˜•íƒœí•™ì  ì—°ì‚°ìœ¼ë¡œ ë…¸ì´ì¦ˆ ì œê±°
            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
            white_mask = cv2.morphologyEx(white_mask, cv2.MORPH_OPEN, kernel)

            processed_for_edges = white_mask
        else:
            processed_for_edges = masked_gray

        # Gaussian blur to reduce noise
        kernel_size = self.get_parameter("blur_kernel_size").value
        blurred = cv2.GaussianBlur(processed_for_edges, (kernel_size, kernel_size), 0)

        # Edge detection
        canny_low = self.get_parameter("canny_low").value
        canny_high = self.get_parameter("canny_high").value
        edges = cv2.Canny(blurred, canny_low, canny_high)

        # êµµì€ ì„ ì„ ì–‡ê²Œ ë§Œë“¤ê¸° (ë¶€ë“œëŸ¬ìš´ ì²˜ë¦¬)
        if self.get_parameter("line_thinning").value:
            # ë„ˆë¬´ ê°•í•œ ìŠ¤ì¼ˆë ˆí†¤í™” ëŒ€ì‹  ë¶€ë“œëŸ¬ìš´ morphology ì—°ì‚° ì‚¬ìš©
            kernel_thin = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
            edges = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel_thin)  # ì—°ê²°
            edges = cv2.morphologyEx(edges, cv2.MORPH_OPEN, kernel_thin)  # ì •ë¦¬

        # ì ì„  ê²€ì¶œì„ ìœ„í•œ ì¶”ê°€ ì „ì²˜ë¦¬ (ì¹´ë©”ë¼ ê°ë„ ê³ ë ¤)
        if self.get_parameter("use_contour_detection").value:
            # ROI ì˜ì—­ì— ë”°ë¼ ë‹¤ë¥¸ í¬ê¸°ì˜ ì»¤ë„ ì‚¬ìš©
            roi_center_y = roi_y + roi_height // 2

            # ë©€ë¦¬ ìˆëŠ” ë¶€ë¶„(ìœ„ìª½)ì€ í° ì»¤ë„, ê°€ê¹Œìš´ ë¶€ë¶„(ì•„ë˜ìª½)ì€ ì‘ì€ ì»¤ë„
            if roi_center_y < height * 0.7:  # ìƒëŒ€ì ìœ¼ë¡œ ë©€ë¦¬ ìˆëŠ” ë¶€ë¶„
                kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (30, 8))
            else:  # ê°€ê¹Œìš´ ë¶€ë¶„
                kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 4))

            edges = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)

        # Choose detection method based on parameter
        detection_method = self.get_parameter("curve_detection_method").value

        # Create visualization image
        processed_image = image.copy()
        cv2.rectangle(
            processed_image, (0, roi_y), (width, roi_y + roi_height), (0, 255, 0), 2
        )

        # Detect line and get visualization data
        line_center = None
        valid_lines = []  # ëª¨ë“  ê²€ì¶œ ë°©ë²•ì—ì„œ ì‚¬ìš©í•  ê¸°ë³¸ê°’

        if detection_method == "moment":
            line_center = self.detect_line_moment_based(edges, roi_y, roi_height)
            # Draw moment-based visualization - center line as vertical red line
            if line_center is not None:
                cv2.line(
                    processed_image,
                    (line_center, roi_y),
                    (line_center, roi_y + roi_height),
                    (0, 0, 255),
                    3,
                )
                # Also draw the edge pixels in red for debugging
                roi_edges = edges[roi_y : roi_y + roi_height, :]
                red_overlay = processed_image[roi_y : roi_y + roi_height, :].copy()
                red_overlay[:, :, 0] = np.maximum(
                    red_overlay[:, :, 0], roi_edges
                )  # Add red channel
                processed_image[roi_y : roi_y + roi_height, :] = red_overlay
        elif detection_method == "contour":
            line_center, largest_contour = self.detect_line_contour_based(edges)
            # Draw the detected contour in red
            if largest_contour is not None:
                cv2.drawContours(processed_image, [largest_contour], -1, (0, 0, 255), 3)
        elif detection_method == "regression":
            line_center, regression_lines = self.detect_line_regression_based(
                edges, roi_y, roi_height, width
            )
            # Draw regression lines
            if regression_lines:
                for line_points in regression_lines:
                    if len(line_points) >= 2:
                        cv2.line(
                            processed_image,
                            tuple(line_points[0]),
                            tuple(line_points[-1]),
                            (0, 0, 255),
                            3,
                        )
        else:  # hough (ê¸°ì¡´ ë°©ì‹)
            line_center, valid_lines = self.detect_line_hough_based(
                edges, roi_y, roi_height
            )
            # Draw the detected lines with left/right color coding
            if valid_lines and self.get_parameter("separate_lanes").value:
                left_lines, right_lines = self.separate_left_right_lines(
                    valid_lines, width
                )
                # ì¢Œì¸¡ ì°¨ì„ : ë¹¨ê°„ìƒ‰, ìš°ì¸¡ ì°¨ì„ : íŒŒë€ìƒ‰
                for x1, y1, x2, y2 in left_lines:
                    cv2.line(
                        processed_image, (x1, y1), (x2, y2), (0, 0, 255), 3
                    )  # ë¹¨ê°„ìƒ‰
                for x1, y1, x2, y2 in right_lines:
                    cv2.line(
                        processed_image, (x1, y1), (x2, y2), (255, 0, 0), 3
                    )  # íŒŒë€ìƒ‰
            elif valid_lines:
                # ê¸°ì¡´ ë°©ì‹: ëª¨ë“  ì„ ì„ ë¹¨ê°„ìƒ‰ìœ¼ë¡œ
                for x1, y1, x2, y2 in valid_lines:
                    cv2.line(processed_image, (x1, y1), (x2, y2), (0, 0, 255), 2)

        # Draw image center reference
        image_center = width // 2
        cv2.line(
            processed_image, (image_center, 0), (image_center, height), (255, 255, 0), 2
        )

        # Draw detected line center if found
        if line_center is not None:
            cv2.circle(
                processed_image,
                (line_center, roi_y + roi_height // 2),
                10,
                (255, 0, 0),
                -1,
            )
            cv2.putText(
                processed_image,
                f"Method: {detection_method}",
                (10, 30),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.7,
                (255, 255, 255),
                2,
            )

            # ì°¨ì„  ì˜ˆì¸¡ ì‹œê°í™” ì¶”ê°€ (ì¢Œìš° ë¶„ë¦¬ ê²€ì¶œ ì‹œì—ë§Œ)
            if (
                self.get_parameter("separate_lanes").value
                and valid_lines
                and detection_method == "hough"
            ):
                left_lines, right_lines = self.separate_left_right_lines(
                    valid_lines, width
                )
                left_center = None
                right_center = None

                if left_lines:
                    left_centers = [(x1 + x2) // 2 for x1, y1, x2, y2 in left_lines]
                    left_center = int(np.mean(left_centers))

                if right_lines:
                    right_centers = [(x1 + x2) // 2 for x1, y1, x2, y2 in right_lines]
                    right_center = int(np.mean(right_centers))

                # ì˜ˆì¸¡ ì‹œê°í™” ì‹¤í–‰
                self.visualize_prediction(
                    processed_image, left_center, right_center, width, roi_y, roi_height
                )

        return line_center, processed_image

    def visualize_prediction(
        self, processed_image, left_center, right_center, image_width, roi_y, roi_height
    ):
        """ì°¨ì„  ì˜ˆì¸¡ ê³¼ì • ì‹œê°í™”"""
        if left_center is not None and right_center is not None:
            # ì–‘ìª½ ì°¨ì„  ëª¨ë‘ ë³´ì´ëŠ” ê²½ìš°
            self.draw_prediction_info(
                processed_image,
                "BOTH LANES",
                f"L:{left_center} R:{right_center}",
                (0, 255, 0),
            )
            # ì°¨ì„  í­ íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
            if self.get_parameter("adaptive_lane_width").value:
                current_width = abs(right_center - left_center)
                self.update_lane_width_history(current_width)
        elif self.get_parameter("curve_prediction").value:
            estimated_width = self.get_estimated_lane_width()

            if left_center is not None:
                # ì¢Œì¸¡ë§Œ ë³´ì´ëŠ” ê²½ìš°
                predicted_right = left_center + estimated_width
                self.draw_predicted_lane(
                    processed_image,
                    predicted_right,
                    roi_y,
                    roi_height,
                    (255, 0, 255),
                    "RIGHT",
                )
                self.draw_prediction_info(
                    processed_image,
                    "LEFT ONLY",
                    f"Est.W:{estimated_width} Pred.R:{predicted_right}",
                    (255, 0, 255),
                )

            elif right_center is not None:
                # ìš°ì¸¡ë§Œ ë³´ì´ëŠ” ê²½ìš°
                predicted_left = right_center - estimated_width
                self.draw_predicted_lane(
                    processed_image,
                    predicted_left,
                    roi_y,
                    roi_height,
                    (255, 255, 0),
                    "LEFT",
                )
                self.draw_prediction_info(
                    processed_image,
                    "RIGHT ONLY",
                    f"Est.W:{estimated_width} Pred.L:{predicted_left}",
                    (255, 255, 0),
                )

    def detect_white_lines_enhanced(self, image):
        """BGR + HSV ì¡°í•©ìœ¼ë¡œ ê°•í™”ëœ í°ìƒ‰ ì„  ê²€ì¶œ - ìš”ì²  í•„í„°ë§ ê°œì„ """
        # HSV ìƒ‰ìƒ ê³µê°„ì—ì„œ í°ìƒ‰ ê²€ì¶œ
        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
        saturation_max = self.get_parameter("saturation_max").value

        # HSVì—ì„œ ì ë‹¹íˆ ê´€ëŒ€í•œ í°ìƒ‰ ë²”ìœ„ (ì°¨ì„  ê²€ì¶œ ìš°ì„ )
        lower_white_hsv = np.array([0, 0, 180])  # ì›ë˜ëŒ€ë¡œ ë³µì›
        upper_white_hsv = np.array([180, saturation_max, 255])  # ì±„ë„ ì œí•œ ì™„í™”
        hsv_white_mask = cv2.inRange(hsv, lower_white_hsv, upper_white_hsv)

        # BGR + HSV ì¡°í•© ì‚¬ìš© ì‹œ
        if self.get_parameter("use_bgr_filtering").value:
            # BGRì—ì„œ ì ë‹¹í•œ í°ìƒ‰ ê²€ì¶œ (ì°¨ì„  ë†“ì¹˜ì§€ ì•Šë„ë¡)
            lower_white_bgr = np.array([210, 210, 210])  # ì„ê³„ê°’ í•˜í–¥ (230â†’210)
            upper_white_bgr = np.array([255, 255, 255])  # ìˆœë°±ìƒ‰
            bgr_white_mask = cv2.inRange(image, lower_white_bgr, upper_white_bgr)

            # ì¢€ ë” ê´€ëŒ€í•œ ì¡°ê±´: OR ì—°ì‚°ìœ¼ë¡œ ê²°í•© (í•©ì§‘í•© - ì°¨ì„  ë†“ì¹˜ì§€ ì•Šê²Œ)
            combined_mask = cv2.bitwise_or(hsv_white_mask, bgr_white_mask)

            # ì¶”ê°€ í•„í„°ë§: ìƒ‰ìƒ ê· ì¼ì„± ê²€ì‚¬
            if self.get_parameter("color_filtering").value:
                combined_mask = self.filter_color_uniformity(image, combined_mask)

            return combined_mask
        else:
            return hsv_white_mask

    def filter_color_uniformity(self, image, mask):
        """ìƒ‰ìƒ ê· ì¼ì„± ê¸°ë°˜ í•„í„°ë§ - ìš”ì² ì˜ ë¶ˆê· ì¼í•œ ìƒ‰ìƒ ì œê±°"""
        # ë§ˆìŠ¤í¬ ì˜ì—­ì—ì„œ BGR í‘œì¤€í¸ì°¨ ê³„ì‚°
        result_mask = mask.copy()

        # ì—°ê²°ëœ ì»´í¬ë„ŒíŠ¸ ì°¾ê¸°
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        for contour in contours:
            # ì‘ì€ ì˜ì—­ì€ ê±´ë„ˆë›°ê¸°
            if cv2.contourArea(contour) < 50:
                continue

            # ì»¨íˆ¬ì–´ ë§ˆìŠ¤í¬ ìƒì„±
            temp_mask = np.zeros_like(mask)
            cv2.fillPoly(temp_mask, [contour], 255)

            # í•´ë‹¹ ì˜ì—­ì˜ ìƒ‰ìƒ ë¶„ì„
            region_pixels = image[temp_mask > 0]
            if len(region_pixels) > 10:
                # BGR ì±„ë„ë³„ í‘œì¤€í¸ì°¨ ê³„ì‚°
                b_std = np.std(region_pixels[:, 0])
                g_std = np.std(region_pixels[:, 1])
                r_std = np.std(region_pixels[:, 2])
                avg_std = (b_std + g_std + r_std) / 3

                # í‘œì¤€í¸ì°¨ê°€ ë§¤ìš° í° ì˜ì—­ë§Œ ì œê±° (ì„ê³„ê°’ ì™„í™”)
                if avg_std > 35:  # ì„ê³„ê°’ ì™„í™” (20â†’35)
                    cv2.fillPoly(result_mask, [contour], 0)

        return result_mask

    def separate_left_right_lines(self, lines, image_width):
        """ì¢Œ/ìš° ì°¨ì„  ë¶„ë¦¬ ê²€ì¶œ"""
        if not lines:
            return [], []

        left_lines = []
        right_lines = []
        image_center = image_width // 2

        for x1, y1, x2, y2 in lines:
            if x2 == x1:  # ìˆ˜ì§ì„  ì œì™¸
                continue

            slope = (y2 - y1) / (x2 - x1)
            center_x = (x1 + x2) // 2

            # ê¸°ìš¸ê¸°ì™€ ìœ„ì¹˜ë¡œ ì¢Œ/ìš° íŒë‹¨
            # ì¢Œì¸¡ ì°¨ì„  (ìŒì˜ ê¸°ìš¸ê¸°)
            if slope < -0.3 and center_x < image_center * 1.2:
                left_lines.append([x1, y1, x2, y2])
            # ìš°ì¸¡ ì°¨ì„  (ì–‘ì˜ ê¸°ìš¸ê¸°)
            elif slope > 0.3 and center_x > image_center * 0.8:
                right_lines.append([x1, y1, x2, y2])

        return left_lines, right_lines

    def update_lane_width_history(self, width):
        """ì°¨ì„  í­ íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸"""
        min_width = self.get_parameter("min_lane_width").value
        max_width = self.get_parameter("max_lane_width").value

        # ìœ íš¨í•œ ë²”ìœ„ ë‚´ì˜ í­ë§Œ ì €ì¥
        if min_width <= width <= max_width:
            self.lane_width_history.append(width)
            if len(self.lane_width_history) > self.max_history_size:
                self.lane_width_history.pop(0)

    def get_estimated_lane_width(self):
        """íˆìŠ¤í† ë¦¬ ê¸°ë°˜ ì¶”ì • ì°¨ì„  í­"""
        if not self.lane_width_history:
            return 300  # ê¸°ë³¸ê°’
        return int(np.median(self.lane_width_history))

    def calculate_center_with_prediction(
        self, left_center, right_center, image_width, processed_image, roi_y, roi_height
    ):
        """ê³¡ì„  ì˜ˆì¸¡ì„ í¬í•¨í•œ ì¤‘ì‹¬ì  ê³„ì‚° + ì‹œê°í™”"""
        if left_center is not None and right_center is not None:
            # ì–‘ìª½ ì°¨ì„  ëª¨ë‘ ë³´ì´ëŠ” ê²½ìš°
            self.draw_prediction_info(
                processed_image,
                "BOTH LANES",
                f"L:{left_center} R:{right_center}",
                (0, 255, 0),
            )
            return (left_center + right_center) // 2

        # ì»¤ë¸Œ ì˜ˆì¸¡ ê¸°ëŠ¥ì´ í™œì„±í™”ëœ ê²½ìš°ë§Œ
        if self.get_parameter("curve_prediction").value:
            estimated_width = self.get_estimated_lane_width()

            if left_center is not None:
                # ì¢Œì¸¡ë§Œ ë³´ì¼ ë•Œ: íˆìŠ¤í† ë¦¬ ê¸°ë°˜ìœ¼ë¡œ ìš°ì¸¡ ì˜ˆì¸¡
                predicted_right = left_center + estimated_width

                # ì˜ˆì¸¡ëœ ìš°ì¸¡ ì°¨ì„  ì‹œê°í™” (ì ì„ ìœ¼ë¡œ)
                self.draw_predicted_lane(
                    processed_image,
                    predicted_right,
                    roi_y,
                    roi_height,
                    (255, 0, 255),
                    "RIGHT",
                )

                # ì´ë¯¸ì§€ ê²½ê³„ ì²´í¬
                if predicted_right < image_width:
                    center = (left_center + predicted_right) // 2
                    self.draw_prediction_info(
                        processed_image,
                        "LEFT ONLY",
                        f"Est.W:{estimated_width} Pred.R:{predicted_right}",
                        (255, 0, 255),
                    )
                    return center
                else:
                    # ìš°ì¸¡ì´ ì´ë¯¸ì§€ë¥¼ ë²—ì–´ë‚˜ë©´ ì¢Œì¸¡ ê¸°ì¤€ìœ¼ë¡œ ì¡°ì •
                    center = min(
                        left_center + estimated_width // 2,
                        image_width - estimated_width // 4,
                    )
                    self.draw_prediction_info(
                        processed_image,
                        "LEFT ONLY (BOUNDARY)",
                        "Adjusted center",
                        (255, 100, 0),
                    )
                    return center

            elif right_center is not None:
                # ìš°ì¸¡ë§Œ ë³´ì¼ ë•Œ: íˆìŠ¤í† ë¦¬ ê¸°ë°˜ìœ¼ë¡œ ì¢Œì¸¡ ì˜ˆì¸¡
                predicted_left = right_center - estimated_width

                # ì˜ˆì¸¡ëœ ì¢Œì¸¡ ì°¨ì„  ì‹œê°í™” (ì ì„ ìœ¼ë¡œ)
                self.draw_predicted_lane(
                    processed_image,
                    predicted_left,
                    roi_y,
                    roi_height,
                    (255, 255, 0),
                    "LEFT",
                )

                # ì´ë¯¸ì§€ ê²½ê³„ ì²´í¬
                if predicted_left >= 0:
                    center = (predicted_left + right_center) // 2
                    self.draw_prediction_info(
                        processed_image,
                        "RIGHT ONLY",
                        f"Est.W:{estimated_width} Pred.L:{predicted_left}",
                        (255, 255, 0),
                    )
                    return center
                else:
                    # ì¢Œì¸¡ì´ ì´ë¯¸ì§€ë¥¼ ë²—ì–´ë‚˜ë©´ ìš°ì¸¡ ê¸°ì¤€ìœ¼ë¡œ ì¡°ì •
                    center = max(
                        right_center - estimated_width // 2, estimated_width // 4
                    )
                    self.draw_prediction_info(
                        processed_image,
                        "RIGHT ONLY (BOUNDARY)",
                        "Adjusted center",
                        (255, 100, 0),
                    )
                    return center
        else:
            # ì˜ˆì¸¡ ê¸°ëŠ¥ ë¹„í™œì„±í™” - ê¸°ì¡´ ê³ ì • ë°©ì‹
            if left_center is not None:
                self.draw_prediction_info(
                    processed_image,
                    "LEFT ONLY (FIXED)",
                    "Fixed offset +150",
                    (128, 128, 128),
                )
                return left_center + 150
            elif right_center is not None:
                self.draw_prediction_info(
                    processed_image,
                    "RIGHT ONLY (FIXED)",
                    "Fixed offset -150",
                    (128, 128, 128),
                )
                return right_center - 150

        # ì–‘ìª½ ëª¨ë‘ ì—†ëŠ” ê²½ìš°
        self.draw_prediction_info(
            processed_image, "NO LANES", "No detection", (0, 0, 255)
        )
        return None

    def draw_predicted_lane(self, image, x_pos, roi_y, roi_height, color, side):
        """ì˜ˆì¸¡ëœ ì°¨ì„ ì„ ì ì„ ìœ¼ë¡œ ê·¸ë¦¬ê¸°"""
        if 0 <= x_pos < image.shape[1]:
            # ì ì„ ìœ¼ë¡œ ì˜ˆì¸¡ ì°¨ì„  í‘œì‹œ
            for y in range(roi_y, roi_y + roi_height, 10):
                if y + 5 < roi_y + roi_height:
                    cv2.line(image, (int(x_pos), y), (int(x_pos), y + 5), color, 2)

            # ì˜ˆì¸¡ í‘œì‹œ í…ìŠ¤íŠ¸
            cv2.putText(
                image,
                f"PRED {side}",
                (int(x_pos) - 30, roi_y - 10),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.5,
                color,
                2,
            )

    def draw_prediction_info(self, image, status, details, color):
        """ì˜ˆì¸¡ ì •ë³´ë¥¼ í™”ë©´ì— í‘œì‹œ"""
        # ìƒíƒœ í‘œì‹œ
        cv2.putText(image, status, (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)

        # ì„¸ë¶€ ì •ë³´ í‘œì‹œ
        cv2.putText(image, details, (10, 85), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)

        # ì°¨ì„  í­ íˆìŠ¤í† ë¦¬ í‘œì‹œ
        if self.lane_width_history:
            avg_width = int(np.mean(self.lane_width_history))
            cv2.putText(
                image,
                f"Avg Width: {avg_width} (n={len(self.lane_width_history)})",
                (10, 110),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.5,
                (255, 255, 255),
                1,
            )

    def calculate_center_with_prediction_simple(
        self, left_center, right_center, image_width
    ):
        """ì‹œê°í™” ì—†ëŠ” ê°„ë‹¨í•œ ì¤‘ì‹¬ì  ê³„ì‚°"""
        if left_center is not None and right_center is not None:
            return (left_center + right_center) // 2

        # ì»¤ë¸Œ ì˜ˆì¸¡ ê¸°ëŠ¥ì´ í™œì„±í™”ëœ ê²½ìš°ë§Œ
        if self.get_parameter("curve_prediction").value:
            estimated_width = self.get_estimated_lane_width()

            if left_center is not None:
                predicted_right = left_center + estimated_width
                if predicted_right < image_width:
                    return (left_center + predicted_right) // 2
                else:
                    return min(
                        left_center + estimated_width // 2,
                        image_width - estimated_width // 4,
                    )

            elif right_center is not None:
                predicted_left = right_center - estimated_width
                if predicted_left >= 0:
                    return (predicted_left + right_center) // 2
                else:
                    return max(
                        right_center - estimated_width // 2, estimated_width // 4
                    )
        else:
            # ê¸°ì¡´ ê³ ì • ë°©ì‹
            if left_center is not None:
                return left_center + 150
            elif right_center is not None:
                return right_center - 150

        return None

    def calculate_lane_center_improved(self, lines, image_width):
        """ì¢Œìš° ë¶„ë¦¬ëœ ì°¨ì„ ìœ¼ë¡œ ë” ì •í™•í•œ ì¤‘ì‹¬ì  ê³„ì‚° + ì ì‘ì  ì°¨ì„  í­"""
        if not self.get_parameter("separate_lanes").value:
            # ê¸°ì¡´ ë°©ì‹ (ëª¨ë“  ì„ ì˜ í‰ê· )
            if not lines:
                return None
            line_centers = [(x1 + x2) // 2 for x1, y1, x2, y2 in lines]
            return int(np.mean(line_centers))

        # ì¢Œìš° ë¶„ë¦¬ ë°©ì‹
        left_lines, right_lines = self.separate_left_right_lines(lines, image_width)

        left_center = None
        right_center = None

        # ì¢Œì¸¡ ì°¨ì„  ì¤‘ì‹¬
        if left_lines:
            left_centers = [(x1 + x2) // 2 for x1, y1, x2, y2 in left_lines]
            left_center = int(np.mean(left_centers))

        # ìš°ì¸¡ ì°¨ì„  ì¤‘ì‹¬
        if right_lines:
            right_centers = [(x1 + x2) // 2 for x1, y1, x2, y2 in right_lines]
            right_center = int(np.mean(right_centers))

        # ì ì‘ì  ì°¨ì„  í­ ì¶”ì •
        if (
            left_center is not None
            and right_center is not None
            and self.get_parameter("adaptive_lane_width").value
        ):
            current_width = abs(right_center - left_center)
            self.update_lane_width_history(current_width)

        # ì°¨ì„  ì¤‘ì•™ì  ê³„ì‚° (ì‹œê°í™”ëŠ” detect_lineì—ì„œ ì²˜ë¦¬)
        return self.calculate_center_with_prediction_simple(
            left_center, right_center, image_width
        )

    def detect_line_regression_based(self, edges, roi_y, roi_height, image_width):
        """ì„ í˜• íšŒê·€ ê¸°ë°˜ ë¼ì¸ ê²€ì¶œ - ë…¸ì´ì¦ˆì— ê°•í•œ ì§ì„ /ê³¡ì„  ê²€ì¶œ"""
        # ROI ì˜ì—­ì—ì„œë§Œ ê²€ì¶œ
        roi_edges = edges[roi_y : roi_y + roi_height, :]

        # ì—£ì§€ í¬ì¸íŠ¸ ì¶”ì¶œ
        edge_points = np.column_stack(np.where(roi_edges > 0))

        if len(edge_points) < self.get_parameter("regression_min_points").value:
            return None, []

        # yì™€ x ì¢Œí‘œ ë³€í™˜ (OpenCV ì¢Œí‘œê³„)
        y_coords = edge_points[:, 0] + roi_y  # ROI offset ì¶”ê°€
        x_coords = edge_points[:, 1]

        # ì¢Œìš° ì°¨ì„  ë¶„ë¦¬ ê²€ì¶œ ì ìš©
        if self.get_parameter("separate_lanes").value:
            return self.detect_lanes_with_regression(
                x_coords, y_coords, image_width, roi_y, roi_height
            )
        else:
            # ë‹¨ì¼ ë¼ì¸ íšŒê·€
            try:
                # 1ì°¨ ë‹¤í•­ì‹ í”¼íŒ… (ì§ì„ )
                coeffs = np.polyfit(y_coords, x_coords, 1)
                poly_func = np.poly1d(coeffs)

                # ì¤‘ì‹¬ì  ê³„ì‚° (ROI ì¤‘ì•™ì—ì„œì˜ x ê°’)
                center_y = roi_y + roi_height // 2
                line_center = int(poly_func(center_y))

                # ì‹œê°í™”ìš© ë¼ì¸ í¬ì¸íŠ¸
                y_line = np.linspace(roi_y, roi_y + roi_height, 50)
                x_line = poly_func(y_line)
                line_points = [
                    [int(x), int(y)]
                    for x, y in zip(x_line, y_line)
                    if 0 <= x < image_width
                ]

                return line_center, [line_points] if line_points else []

            except (np.linalg.LinAlgError, np.RankWarning):
                return None, []

    def detect_lanes_with_regression(
        self, x_coords, y_coords, image_width, roi_y, roi_height
    ):
        """ì¢Œìš° ì°¨ì„ ì„ ë¶„ë¦¬í•˜ì—¬ ê°ê° íšŒê·€ ë¶„ì„"""
        image_center = image_width // 2

        # ì¢Œìš° ë¶„ë¦¬
        left_mask = x_coords < image_center * 1.2
        right_mask = x_coords > image_center * 0.8

        left_x = x_coords[left_mask]
        left_y = y_coords[left_mask]
        right_x = x_coords[right_mask]
        right_y = y_coords[right_mask]

        min_points = self.get_parameter("regression_min_points").value // 2

        left_line = None
        right_line = None
        regression_lines = []

        # ì¢Œì¸¡ ì°¨ì„  íšŒê·€
        if len(left_x) >= min_points:
            try:
                left_coeffs = np.polyfit(left_y, left_x, 1)
                left_func = np.poly1d(left_coeffs)

                # ì‹œê°í™”ìš© í¬ì¸íŠ¸
                y_line = np.linspace(roi_y, roi_y + roi_height, 30)
                x_line = left_func(y_line)
                left_points = [
                    [int(x), int(y)]
                    for x, y in zip(x_line, y_line)
                    if 0 <= x < image_width
                ]
                if left_points:
                    regression_lines.append(left_points)
                    left_line = int(left_func(roi_y + roi_height // 2))
            except (np.linalg.LinAlgError, np.RankWarning):
                pass
        # ìš°ì¸¡ ì°¨ì„  íšŒê·€
        if len(right_x) >= min_points:
            try:
                right_coeffs = np.polyfit(right_y, right_x, 1)
                right_func = np.poly1d(right_coeffs)

                # ì‹œê°í™”ìš© í¬ì¸íŠ¸
                y_line = np.linspace(roi_y, roi_y + roi_height, 30)
                x_line = right_func(y_line)
                right_points = [
                    [int(x), int(y)]
                    for x, y in zip(x_line, y_line)
                    if 0 <= x < image_width
                ]
                if right_points:
                    regression_lines.append(right_points)
                    right_line = int(right_func(roi_y + roi_height // 2))
            except (np.linalg.LinAlgError, np.RankWarning):
                pass

        # ì¤‘ì‹¬ì  ê³„ì‚°
        if left_line is not None and right_line is not None:
            line_center = (left_line + right_line) // 2
        elif left_line is not None:
            line_center = left_line + 150  # ì¢Œì¸¡ë§Œ ìˆìœ¼ë©´ ìš°ì¸¡ ì¶”ì •
        elif right_line is not None:
            line_center = right_line - 150  # ìš°ì¸¡ë§Œ ìˆìœ¼ë©´ ì¢Œì¸¡ ì¶”ì •
        else:
            return None, []

        return line_center, regression_lines

    def detect_line_moment_based(self, edges, roi_y, roi_height):
        """ëª¨ë©˜íŠ¸ ê¸°ë°˜ ì¤‘ì‹¬ì„  ê²€ì¶œ - ê³¡ì„ ì— ìµœê³  ì„±ëŠ¥"""
        # ROI ì˜ì—­ì—ì„œë§Œ ëª¨ë©˜íŠ¸ ê³„ì‚°
        roi_edges = edges[roi_y : roi_y + roi_height, :]

        # ê° í–‰(yì¢Œí‘œ)ë³„ë¡œ ì¤‘ì‹¬ì  ê³„ì‚°
        centers = []
        weights = []  # ê°€ì¤‘ì¹˜ (ë” ê°•í•œ ì‹ í˜¸ì¼ìˆ˜ë¡ ë†’ì€ ê°€ì¤‘ì¹˜)

        for y_idx, y in enumerate(range(roi_edges.shape[0])):
            row = roi_edges[y, :]
            white_pixels = np.where(row > 0)[0]

            if len(white_pixels) > 0:
                # ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ì¤‘ì‹¬ì  ê³„ì‚°
                weights_row = row[white_pixels].astype(float)
                if np.sum(weights_row) > 0:
                    center_x = np.average(white_pixels, weights=weights_row)
                    centers.append(center_x)
                    # ê°€ê¹Œìš´ í–‰ì¼ìˆ˜ë¡ ë” ì¤‘ìš”í•˜ê²Œ (ë¡œë´‡ì— ê°€ê¹Œìš´ ë¶€ë¶„)
                    weight = np.sum(weights_row) * (y_idx + 1)
                    weights.append(weight)

        if centers and weights:
            # ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ìµœì¢… ì¤‘ì‹¬ì  ê³„ì‚°
            final_center = np.average(centers, weights=weights)
            return int(final_center)
        return None

    def detect_line_contour_based(self, edges):
        """ì»¨íˆ¬ì–´ ê¸°ë°˜ ì¤‘ì‹¬ì„  ê²€ì¶œ - ê³¡ì„ ì— ì í•©"""
        # Find contours
        contours, _ = cv2.findContours(
            edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE
        )

        if not contours:
            return None, None

        # Get largest contour (main line)
        largest_contour = max(contours, key=cv2.contourArea)

        # ìµœì†Œ ë©´ì  ì²´í¬
        if cv2.contourArea(largest_contour) < 50:
            return None, None

        # Calculate moments to find centroid
        M = cv2.moments(largest_contour)
        if M["m00"] != 0:
            cx = int(M["m10"] / M["m00"])
            return cx, largest_contour
        return None, None

    def detect_line_hough_based(self, edges, roi_y, roi_height):
        """ê¸°ì¡´ Hough Transform ë°©ì‹ - ì§ì„ ì—ë§Œ ì í•©"""
        min_line_length = self.get_parameter("min_line_length").value
        max_line_gap = self.get_parameter("max_line_gap").value

        lines = cv2.HoughLinesP(
            edges,
            rho=1,
            theta=np.pi / 360,
            threshold=12,
            minLineLength=min_line_length,
            maxLineGap=max_line_gap,
        )

        if lines is None:
            return None, []

        # Filter and average lines
        valid_lines = []
        for line in lines:
            x1, y1, x2, y2 = line[0]
            angle = np.arctan2(y2 - y1, x2 - x1) * 180 / np.pi
            if abs(angle) > 15 and abs(angle) < 165:
                valid_lines.append(line[0])

        if valid_lines:
            # ê°œì„ ëœ ì¤‘ì‹¬ì  ê³„ì‚° (ì¢Œìš° ë¶„ë¦¬ ê³ ë ¤)
            line_center = self.calculate_lane_center_improved(
                valid_lines, 640
            )  # ê¸°ë³¸ ì´ë¯¸ì§€ í­
            return line_center, valid_lines
        return None, []

    def merge_nearby_lines(self, lines, distance_threshold=20):
        """ê°€ê¹Œìš´ ì„ ë“¤ì„ ë³‘í•©í•˜ì—¬ êµµì€ ì„ ì´ ë‘ ê°œë¡œ ì¸ì‹ë˜ëŠ” ê²ƒ ë°©ì§€"""
        if len(lines) <= 1:
            return lines

        merged_lines = []
        used = [False] * len(lines)

        for i, line1 in enumerate(lines):
            if used[i]:
                continue

            x1, y1, x2, y2 = line1
            center1 = ((x1 + x2) // 2, (y1 + y2) // 2)
            similar_lines = [line1]
            used[i] = True

            # í˜„ì¬ ì„ ê³¼ ê°€ê¹Œìš´ ì„ ë“¤ ì°¾ê¸°
            for j, line2 in enumerate(lines):
                if used[j] or i == j:
                    continue

                x3, y3, x4, y4 = line2
                center2 = ((x3 + x4) // 2, (y3 + y4) // 2)

                # ì¤‘ì‹¬ì  ê°„ ê±°ë¦¬ ê³„ì‚°
                distance = np.sqrt(
                    (center1[0] - center2[0]) ** 2 + (center1[1] - center2[1]) ** 2
                )

                # ê°ë„ ì°¨ì´ ê³„ì‚°
                angle1 = np.arctan2(y2 - y1, x2 - x1)
                angle2 = np.arctan2(y4 - y3, x4 - x3)
                angle_diff = abs(angle1 - angle2) * 180 / np.pi

                # ê°€ê¹Œìš°ë©´ì„œ ë¹„ìŠ·í•œ ê°ë„ì˜ ì„ ë“¤ ë³‘í•©
                if distance < distance_threshold and angle_diff < 30:
                    similar_lines.append(line2)
                    used[j] = True

            # ë³‘í•©ëœ ì„ ë“¤ì˜ í‰ê· ìœ¼ë¡œ ìƒˆë¡œìš´ ì„  ìƒì„±
            if len(similar_lines) > 1:
                avg_x1 = int(np.mean([line[0] for line in similar_lines]))
                avg_y1 = int(np.mean([line[1] for line in similar_lines]))
                avg_x2 = int(np.mean([line[2] for line in similar_lines]))
                avg_y2 = int(np.mean([line[3] for line in similar_lines]))
                merged_lines.append([avg_x1, avg_y1, avg_x2, avg_y2])
            else:
                merged_lines.append(line1)

        return merged_lines

    def follow_line(self, line_center, image_width):
        """Generate control commands to follow the detected line"""
        image_center = image_width // 2
        error = line_center - image_center

        # PID Controller
        kp = self.get_parameter("kp").value
        ki = self.get_parameter("ki").value
        kd = self.get_parameter("kd").value

        # Calculate PID terms
        proportional = error
        self.integral_error += error
        derivative = error - self.previous_error

        # PID output
        pid_output = kp * proportional + ki * self.integral_error + kd * derivative

        # Create control command
        cmd = Twist()
        cmd.linear.x = self.get_parameter("linear_speed").value
        cmd.angular.z = -pid_output * self.get_parameter("angular_gain").value

        # Limit angular velocity
        max_angular = 1.0
        cmd.angular.z = max(-max_angular, min(max_angular, cmd.angular.z))

        # Debug: ëª…ë ¹ì–´ ë¡œê¹… ê°•í™”
        self.get_logger().info(
            f"ğŸš— MOVE: linear.x={cmd.linear.x:.3f}, "
            f"angular.z={cmd.angular.z:.3f}, error={error}"
        )

        # Publish command
        self.cmd_vel_publisher.publish(cmd)

        # Update previous error
        self.previous_error = error

        self.get_logger().info(
            f"Line following: error={error}, angular_z={cmd.angular.z:.3f}"
        )

    def stop_robot(self):
        """Stop the robot when no line is detected"""
        cmd = Twist()
        cmd.linear.x = 0.0
        cmd.angular.z = 0.0
        self.cmd_vel_publisher.publish(cmd)
        self.get_logger().warn("ğŸ›‘ STOP: No line detected - stopping robot")

    def publish_processed_image(self, cv_image):
        """Publish processed image for visualization"""
        try:
            ros_image = self.bridge.cv2_to_imgmsg(cv_image, "bgr8")
            ros_image.header.stamp = self.get_clock().now().to_msg()
            ros_image.header.frame_id = "camera_link"
            self.processed_image_publisher.publish(ros_image)
        except Exception as e:
            self.get_logger().error(f"Failed to publish processed image: {str(e)}")


def main(args=None):
    rclpy.init(args=args)

    try:
        node = LineFollowerNode()
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        if "node" in locals():
            node.destroy_node()
        rclpy.shutdown()


if __name__ == "__main__":
    main()
